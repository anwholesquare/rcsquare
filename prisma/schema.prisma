// This is your Prisma schema file,
// learn more about it in the docs: https://pris.ly/d/prisma-schema

// Looking for ways to speed up your queries, or scale easily with your serverless or edge functions?
// Try Prisma Accelerate: https://pris.ly/cli/accelerate-init

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "mysql"
  url      = env("DATABASE_URL")
}

model Project {
  id        String    @id @default(cuid())
  name      String    @unique
  createdAt DateTime  @default(now())
  updatedAt DateTime  @updatedAt
  videos    Video[]
  searches  SearchHistory[]

  @@map("projects")
}

model Video {
  id          String   @id @default(cuid())
  projectId   String
  title       String
  description String?  @db.Text
  tags        String?  @db.Text
  filename    String
  originalUrl String?  @db.Text
  fileSize    Int?
  duration    Float?
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
  
  // Frame analysis data
  frameAnalysis VideoFrameAnalysis?
  
  // Transcription data
  transcription VideoTranscription?
  
  // Summarization data
  segments VideoSegment[]
  topics   VideoTopic[]
  
  project Project @relation(fields: [projectId], references: [id], onDelete: Cascade)

  @@map("videos")
}

model VideoFrameAnalysis {
  id             String   @id @default(cuid())
  videoId        String   @unique
  frameSampling  Int      @default(5) // seconds between frames
  status         String   @default("pending") // pending, processing, completed, failed
  totalFrames    Int?
  processedAt    DateTime?
  createdAt      DateTime @default(now())
  updatedAt      DateTime @updatedAt
  
  video          Video    @relation(fields: [videoId], references: [id], onDelete: Cascade)
  frames         VideoFrame[]
  captions       VideoCaption[]
  persons        VideoPerson[]

  @@map("video_frame_analysis")
}

model VideoFrame {
  id           String   @id @default(cuid())
  analysisId   String
  timestamp    String   // format: "HH.MM.SS"
  imageLink    String   @db.Text
  clipEmbedding String? @db.LongText // JSON string of embedding
  createdAt    DateTime @default(now())
  
  analysis     VideoFrameAnalysis @relation(fields: [analysisId], references: [id], onDelete: Cascade)

  @@map("video_frames")
}

model VideoCaption {
  id               String   @id @default(cuid())
  analysisId       String
  timestamp        String   // format: "HH.MM.SS"
  imageLink        String   @db.Text
  caption          String   @db.Text
  captionEmbedding String?  @db.LongText // JSON string of embedding
  createdAt        DateTime @default(now())
  
  analysis         VideoFrameAnalysis @relation(fields: [analysisId], references: [id], onDelete: Cascade)

  @@map("video_captions")
}

model VideoPerson {
  id            String   @id @default(cuid())
  analysisId    String
  timestamp     String   // format: "HH.MM.SS"
  imageLink     String   @db.Text
  personUid     String   // unique identifier for the detected person
  clipEmbedding String?  @db.LongText // JSON string of embedding
  createdAt     DateTime @default(now())
  
  analysis      VideoFrameAnalysis @relation(fields: [analysisId], references: [id], onDelete: Cascade)

  @@map("video_persons")
}

model VideoTranscription {
  id             String   @id @default(cuid())
  videoId        String   @unique
  status         String   @default("pending") // pending, processing, completed, failed
  model          String   @default("whisper-base") // transcription model used
  language       String?  // detected/specified language
  totalSegments  Int?
  totalDuration  Float?   // total audio duration in seconds
  processedAt    DateTime?
  errorMessage   String?  @db.Text
  createdAt      DateTime @default(now())
  updatedAt      DateTime @updatedAt
  
  video          Video    @relation(fields: [videoId], references: [id], onDelete: Cascade)
  segments       VideoTranscriptionSegment[]

  @@map("video_transcriptions")
}

model VideoTranscriptionSegment {
  id                 String   @id @default(cuid())
  transcriptionId    String
  segmentIndex       Int      // order of segment in the transcription
  startingTimestamp  String   // format: "HH.MM.SS"
  endingTimestamp    String   // format: "HH.MM.SS"
  startSeconds       Float    // start time in seconds for easier querying
  endSeconds         Float    // end time in seconds for easier querying
  transcription      String   @db.Text // original transcription
  refinedTranscription String? @db.Text // LLM-refined transcription
  confidence         Float?   // confidence score from Whisper
  isEdited           Boolean  @default(false) // whether user has manually edited
  createdAt          DateTime @default(now())
  updatedAt          DateTime @updatedAt
  
  videoTranscription VideoTranscription @relation(fields: [transcriptionId], references: [id], onDelete: Cascade)

  @@map("video_transcription_segments")
}

model VideoSegment {
  id                String   @id @default(cuid())
  videoId           String
  segmentIndex      Int      // order of segment in the video
  startingTimestamp String   // format: "HH.MM.SS"
  endingTimestamp   String   // format: "HH.MM.SS"
  startSeconds      Float    // start time in seconds for easier querying
  endSeconds        Float    // end time in seconds for easier querying
  description       String   @db.Text // AI-generated segment description
  status            String   @default("pending") // pending, processing, completed, failed
  model             String?  // GPT model used for generation
  createdAt         DateTime @default(now())
  updatedAt         DateTime @updatedAt
  
  video             Video    @relation(fields: [videoId], references: [id], onDelete: Cascade)

  @@map("video_segments")
}

model VideoTopic {
  id                String   @id @default(cuid())
  videoId           String
  topicIndex        Int      // order of topic in the video
  startingTimestamp String   // format: "HH.MM.SS"
  endingTimestamp   String   // format: "HH.MM.SS"
  startSeconds      Float    // start time in seconds for easier querying
  endSeconds        Float    // end time in seconds for easier querying
  topic             String   @db.Text // AI-generated contextual topic
  status            String   @default("pending") // pending, processing, completed, failed
  model             String?  // GPT model used for generation
  createdAt         DateTime @default(now())
  updatedAt         DateTime @updatedAt
  
  video             Video    @relation(fields: [videoId], references: [id], onDelete: Cascade)

  @@map("video_topics")
}

model TokenUsage {
  id           String   @id @default(cuid())
  videoId      String?  // optional, for video-specific operations
  operation    String   // operation type: "summarization", "topic_generation", etc.
  model        String   // GPT model used
  promptTokens Int      // input tokens used
  completionTokens Int  // output tokens generated
  totalTokens  Int      // total tokens used
  cost         Float?   // estimated cost in USD
  requestData  String?  @db.LongText // JSON of request details
  responseData String?  @db.LongText // JSON of response details
  createdAt    DateTime @default(now())

  @@map("token_usage")
}

model SearchHistory {
  id         String   @id @default(cuid())
  projectId  String   // project where search was performed
  query      String   @db.Text // search query or image name
  searchType String   // "text", "person", "frame"
  results    String   @db.LongText // JSON array of search results
  tokenUsage Int?     // tokens used for AI search
  cost       Float?   // estimated cost in USD
  model      String?  // AI model used for search
  metadata   String?  @db.LongText // additional search metadata (similarity scores, etc.)
  createdAt  DateTime @default(now())
  
  project    Project  @relation(fields: [projectId], references: [id], onDelete: Cascade)

  @@map("search_history")
}
